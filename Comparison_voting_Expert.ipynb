{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expert of SVM -- differents type of voting system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from typing import Dict, List, Tuple\n",
    "import pickle\n",
    "import warnings\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from google.colab import files\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Learn++.NC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnPPNC:\n",
    "    \"\"\"\n",
    "    Learn++.NC with SVM.\n",
    "    Votes : expert predict a class, weighted by its training accuracy. The class with the most weighted votes wins.\n",
    "    confiance: predict_proba\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, optimize: bool = True, C: float = 10.0, gamma: float = 0.1,\n",
    "                 n_trials: int = 50, cv_folds: int = 3, verbose: bool = True):\n",
    "        self.optimize = optimize\n",
    "        self.default_C = C\n",
    "        self.default_gamma = gamma\n",
    "        self.n_trials = n_trials\n",
    "        self.cv_folds = cv_folds\n",
    "        self.verbose = verbose\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.scaler: StandardScaler = None\n",
    "        self.experts: List[Dict] = []\n",
    "        self.all_classes: set = set()\n",
    "        self.is_initialized = False\n",
    "        self.optuna_study = None\n",
    "        self.history: List[Dict] = []\n",
    "    \n",
    "    def _log(self, msg: str):\n",
    "        if self.verbose:\n",
    "            print(msg)\n",
    "    \n",
    "    def _optimize_hyperparams(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"Optimization Using optuna \"\"\"\n",
    "        self._log(\"OPTIMISATION OPTUNA\")\n",
    "        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=42)\n",
    "        # research space for C and gamma with CV accuracy as objective \n",
    "        def objective(trial):\n",
    "            C = trial.suggest_float('C', 1e-1, 1e4, log=True)\n",
    "            gamma = trial.suggest_float('gamma', 1e-4, 1e1, log=True)\n",
    "            svc = SVC(C=C, gamma=gamma, kernel='rbf', class_weight='balanced')\n",
    "            scores = cross_val_score(svc, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "            return scores.mean()\n",
    "        \n",
    "        self.optuna_study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            sampler=TPESampler(seed=42)\n",
    "        )\n",
    "        self.optuna_study.optimize(\n",
    "            objective,\n",
    "            n_trials=self.n_trials,\n",
    "            show_progress_bar=self.verbose\n",
    "        )\n",
    "        \n",
    "        self.C = self.optuna_study.best_params['C']\n",
    "        self.gamma = self.optuna_study.best_params['gamma']\n",
    "        \n",
    "        self._log(f\"\\nBest Datas :\")\n",
    "        self._log(f\"  C = {self.C:.4f}\")\n",
    "        self._log(f\"  gamma = {self.gamma:.6f}\")\n",
    "        self._log(f\"  CV Accuracy = {self.optuna_study.best_value:.4f}\")\n",
    "    \n",
    "    def add_data(self, X: np.ndarray, y: np.ndarray, name: str = None):\n",
    "        \"\"\"\n",
    "        To create new expert.\n",
    "        \"\"\"\n",
    "        X = np.atleast_2d(X)\n",
    "        y = np.array(y)\n",
    "        name = name or f\"Batch_{len(self.experts) + 1}\"\n",
    "        \n",
    "        classes_in_batch = set(np.unique(y))\n",
    "        new_classes = classes_in_batch - self.all_classes\n",
    "        \n",
    "        self._log(f\"{name}\")\n",
    "        self._log(f\"   samples: {len(y)}\")\n",
    "        self._log(f\"   Class: {sorted(classes_in_batch)}\")\n",
    "        if new_classes:\n",
    "            self._log(f\"   new class: {sorted(new_classes)}\")\n",
    "        \n",
    "        if not self.is_initialized:\n",
    "            self.scaler = StandardScaler()\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "            \n",
    "            if self.optimize:\n",
    "                self._optimize_hyperparams(X_scaled, y)\n",
    "            else:\n",
    "                self.C = self.default_C\n",
    "                self.gamma = self.default_gamma\n",
    "                self._log(f\"\\nParameters: C={self.C}, gamma={self.gamma}\")\n",
    "            \n",
    "            self.is_initialized = True\n",
    "        \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        #voir sklearn SVC \n",
    "        clf = SVC(\n",
    "            C=self.C,\n",
    "            gamma=self.gamma,\n",
    "            kernel='rbf',\n",
    "            class_weight='balanced',\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        clf.fit(X_scaled, y)\n",
    "        \n",
    "        y_pred_train = clf.predict(X_scaled)\n",
    "        accuracy = accuracy_score(y, y_pred_train)\n",
    "        \n",
    "        expert = {\n",
    "            'clf': clf,\n",
    "            'accuracy': accuracy,\n",
    "            'classes': classes_in_batch,\n",
    "            'name': name,\n",
    "            'n_sv': len(clf.support_),\n",
    "            'n_samples': len(y)\n",
    "        }\n",
    "        self.experts.append(expert)\n",
    "        self.all_classes.update(classes_in_batch)\n",
    "        \n",
    "        self.history.append({\n",
    "            'name': name,\n",
    "            'n_samples': len(y),\n",
    "            'n_classes': len(classes_in_batch),\n",
    "            'new_classes': list(new_classes),\n",
    "            'accuracy': accuracy,\n",
    "            'n_sv': len(clf.support_),\n",
    "            'expert_id': len(self.experts)\n",
    "        })\n",
    "        \n",
    "        self._log(f\"\\n✓ Expert #{len(self.experts)} creaeed: {name}\")\n",
    "        self._log(f\"   Accuracy (train): {accuracy:.4f}\")\n",
    "        return self\n",
    "    \n",
    "    def predict_with_details(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \n",
    "        X = np.atleast_2d(X)\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        all_classes = np.array(sorted(self.all_classes))\n",
    "        n_classes = len(all_classes)\n",
    "        class_to_idx = {c: i for i, c in enumerate(all_classes)}\n",
    "        \n",
    "        vote_matrix = np.zeros((n_samples, n_classes))\n",
    "        prob_matrix = np.zeros((n_samples, n_classes))\n",
    "        total_weight = 0.0\n",
    "        \n",
    "        for expert in self.experts:\n",
    "            clf = expert['clf']\n",
    "            weight = expert['accuracy']\n",
    "            total_weight += weight\n",
    "            \n",
    "            pred = clf.predict(X_scaled)\n",
    "            proba = clf.predict_proba(X_scaled)\n",
    "            expert_classes = clf.classes_\n",
    "            \n",
    "            for i in range(n_samples):\n",
    "                if pred[i] in class_to_idx:\n",
    "                    vote_matrix[i, class_to_idx[pred[i]]] += weight\n",
    "                for j, c in enumerate(expert_classes):\n",
    "                    if c in class_to_idx:\n",
    "                        prob_matrix[i, class_to_idx[c]] += weight * proba[i, j]\n",
    "        \n",
    "        prob_matrix /= total_weight\n",
    "        y_pred = all_classes[np.argmax(vote_matrix, axis=1)]\n",
    "        confidence = np.max(prob_matrix, axis=1)\n",
    "        \n",
    "        return y_pred, confidence, vote_matrix\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        y_pred, _, _ = self.predict_with_details(X)\n",
    "        return y_pred\n",
    "    \n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        _, _, vote_matrix = self.predict_with_details(X)\n",
    "        return vote_matrix / vote_matrix.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray, y: np.ndarray) -> Dict:\n",
    "        y_pred, confidence, vote_matrix = self.predict_with_details(X)\n",
    "        all_classes = np.array(sorted(self.all_classes))\n",
    "        return {\n",
    "            'accuracy': accuracy_score(y, y_pred),\n",
    "            'y_true': y,\n",
    "            'y_pred': y_pred,\n",
    "            'confidence': confidence,\n",
    "            'vote_matrix': vote_matrix,\n",
    "            'confusion_matrix': confusion_matrix(y, y_pred, labels=all_classes),\n",
    "            'classes': all_classes\n",
    "        }\n",
    "    \n",
    "    def get_expert_predictions(self, X: np.ndarray) -> pd.DataFrame:\n",
    "        \"\"\"prediction of each expert + confidence\"\"\"\n",
    "        X_scaled = self.scaler.transform(np.atleast_2d(X))\n",
    "        results = {'sample_idx': list(range(len(X_scaled)))}\n",
    "        for i, expert in enumerate(self.experts):\n",
    "            pred = expert['clf'].predict(X_scaled)\n",
    "            proba = expert['clf'].predict_proba(X_scaled)\n",
    "            max_proba = np.max(proba, axis=1)\n",
    "            results[f'expert_{i+1}_pred'] = pred\n",
    "            results[f'expert_{i+1}_conf'] = max_proba\n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def save(self, filepath: str):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        self._log(f\"Model Saved: {filepath}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filepath: str) -> 'LearnPPNC':\n",
    "        with open(filepath, 'rb') as f:\n",
    "            return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fonctions de Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optuna(model):\n",
    "    \"\"\"Optuna.\"\"\"\n",
    "    if model.optuna_study is None:\n",
    "        return\n",
    "    \n",
    "    trials_df = model.optuna_study.trials_dataframe()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 1, figsize=(15, 4))\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.plot(trials_df.index, trials_df['value'], 'b.', alpha=0.3, label='Trials')\n",
    "    ax.plot(trials_df.index, trials_df['value'].cummax(), 'r-', lw=2, label='Best')\n",
    "    ax.axhline(model.optuna_study.best_value, color='green', ls='--', label=f'Final: {model.optuna_study.best_value:.4f}')\n",
    "    ax.set_xlabel('Trial')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Convergence Optuna')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('optuna_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_experts_summary(model):\n",
    "    \"\"\"Résumé des experts.\"\"\"\n",
    "    if len(model.experts) == 0:\n",
    "        print(\"Aucun expert.\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "    \n",
    "    names = [e['name'] for e in model.experts]\n",
    "    accuracies = [e['accuracy'] for e in model.experts]\n",
    "    n_svs = [e['n_sv'] for e in model.experts]\n",
    "    n_samples = [e['n_samples'] for e in model.experts]\n",
    "    \n",
    "    ax = axes[0]\n",
    "    bars = ax.bar(range(len(names)), accuracies, color='steelblue', edgecolor='black')\n",
    "    ax.axhline(np.mean(accuracies), color='red', ls='--', label=f'Moyenne: {np.mean(accuracies):.4f}')\n",
    "    ax.set_xticks(range(len(names)))\n",
    "    ax.set_xticklabels([f'E{i+1}' for i in range(len(names))], rotation=0)\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Accuracy par Expert')\n",
    "    ax.set_ylim([min(0.9, min(accuracies)-0.05), 1.0])\n",
    "    ax.legend()\n",
    "    for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, f'{acc:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('experts_summary.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(results, title='Confusion Matrix'):\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    cm = results['confusion_matrix']\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    classes = results['classes']\n",
    "    \n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=classes.astype(int),\n",
    "                yticklabels=classes.astype(int),\n",
    "                ax=ax, vmin=0, vmax=1,\n",
    "                cbar_kws={'label': 'Proportion'})\n",
    "    \n",
    "    ax.set_xlabel('Prediction', fontsize=12)\n",
    "    ax.set_ylabel('Real Class', fontsize=12)\n",
    "    ax.set_title(f\"{title}\\nAccuracy: {results['accuracy']:.2%}\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_class_performance(results):\n",
    "    \"\"\"Performance par classe.\"\"\"\n",
    "    y_true = results['y_true']\n",
    "    y_pred = results['y_pred']\n",
    "    classes = results['classes']\n",
    "    \n",
    "    class_acc = []\n",
    "    class_count = []\n",
    "    for c in classes:\n",
    "        mask = y_true == c\n",
    "        if np.sum(mask) > 0:\n",
    "            class_acc.append(np.mean(y_pred[mask] == c))\n",
    "            class_count.append(np.sum(mask))\n",
    "        else:\n",
    "            class_acc.append(0)\n",
    "            class_count.append(0)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    ax = axes[0]\n",
    "    colors = ['green' if a > 0.9 else 'orange' if a > 0.7 else 'red' for a in class_acc]\n",
    "    bars = ax.bar(range(len(classes)), class_acc, color=colors, edgecolor='black')\n",
    "    ax.axhline(results['accuracy'], color='blue', ls='--', lw=2, label=f'Accuracy globale: {results[\"accuracy\"]:.4f}')\n",
    "    ax.set_xticks(range(len(classes)))\n",
    "    ax.set_xticklabels([int(c) for c in classes])\n",
    "    ax.set_xlabel('Classe')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Accuracy par Classe')\n",
    "    ax.set_ylim([0, 1.05])\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.bar(range(len(classes)), class_count, color='steelblue', edgecolor='black')\n",
    "    ax.set_xticks(range(len(classes)))\n",
    "    ax.set_xticklabels([int(c) for c in classes])\n",
    "    ax.set_xlabel('Classe')\n",
    "    ax.set_ylabel(\"Nombre d'échantillons\")\n",
    "    ax.set_title('Distribution des Classes (Test)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('class_performance.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = [\n",
    "    'Electrical speed [rad/s]',\n",
    "    'I_M_a', 'I_M_b', 'I_M_c',\n",
    "    'I_P_a', 'I_P_b', 'I_P_c',\n",
    "    'I_B_a', 'I_B_b', 'I_B_c',\n",
    "    'V_M_a', 'V_M_b', 'V_M_c',\n",
    "    'V_P_a', 'V_P_b', 'V_P_c',\n",
    "    'V_B_a', 'V_B_b', 'V_B_c'\n",
    "]\n",
    "LABEL_COL = 'Class label'\n",
    "\n",
    "def load_file(filepath):\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    X = df[FEATURE_COLS].values\n",
    "    y = df[LABEL_COL].values\n",
    "    print(f\"Chargé: {len(y)} échantillons, {len(np.unique(y))} classes\")\n",
    "    print(f\"Classes: {sorted(np.unique(y))}\")\n",
    "    return X, y, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# CHARGEMENT & SÉPARATION CONNUES / NOUVELLES\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FICHIER:\")\n",
    "uploaded = files.upload()\n",
    "file_name = list(uploaded.keys())[0]\n",
    "X_all, y_all, df = load_file(file_name)\n",
    "\n",
    "print(f\"\\nDistribution:\")\n",
    "for c in sorted(np.unique(y_all)):\n",
    "    print(f\"  Classes {c:2d} : {np.sum(y_all == c):4d} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_CLASSES = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "NEW_CLASSES   = [9, 10, 11, 12, 13, 14, 15, 16]\n",
    "\n",
    "print(f\"Classes known  : {KNOWN_CLASSES}\")\n",
    "print(f\"Classes unknown: {NEW_CLASSES}\")\n",
    "\n",
    "mask_known = np.isin(y_all, KNOWN_CLASSES)\n",
    "mask_new   = np.isin(y_all, NEW_CLASSES)\n",
    "\n",
    "X_known = X_all[mask_known]\n",
    "y_known = y_all[mask_known]\n",
    "X_new = X_all[mask_new]\n",
    "y_new = y_all[mask_new]\n",
    "\n",
    "X_known_train, X_known_test, y_known_train, y_known_test = train_test_split(\n",
    "    X_known, y_known, test_size=0.2, stratify=y_known, random_state=42\n",
    ")\n",
    "X_new_train, X_new_test, y_new_train, y_new_test = train_test_split(\n",
    "    X_new, y_new, test_size=0.2, stratify=y_new, random_state=42\n",
    ")\n",
    "\n",
    "X_test_all = np.vstack([X_known_test, X_new_test])\n",
    "y_test_all = np.hstack([y_known_test, y_new_test])\n",
    "\n",
    "print(f\"\\nKnown - Train: {len(y_known_train)}, Test: {len(y_known_test)}\")\n",
    "print(f\"New   - Train: {len(y_new_train)},   Test: {len(y_new_test)}\")\n",
    "print(f\"Test total:    {len(y_test_all)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# APPRENTISSAGE INCRÉMENTAL\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LearnPPNC(optimize=True, n_trials=100, cv_folds=3, verbose=True)\n",
    "\n",
    "# Sans Optuna (plus rapide):\n",
    "# model = LearnPPNC(optimize=False, C=100, gamma=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_data(X_known_train, y_known_train, name=\"Expert_1_Known\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optuna(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test on E1\")\n",
    "results_e1 = model.evaluate(X_known_test, y_known_test)\n",
    "print(f\"\\nACCURACY E1: {results_e1['accuracy']:.4f}\")\n",
    "print(classification_report(results_e1['y_true'], results_e1['y_pred'], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(results_e1, 'Expert 1 - Classes Connues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_data(X_new_train, y_new_train, name=\"Expert_2_New\")\n",
    "\n",
    "print(f\"\\nNombre d'experts: {len(model.experts)}\")\n",
    "print(f\"Classes totales: {sorted(model.all_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experts_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# COMPARAISON DES STRATÉGIES DE VOTE\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MÉTHODE 1 : Vote Pondéré Basique\")\n",
    "print(\"=\"*60)\n",
    "print(\"Chaque expert vote pour sa prédiction, pondéré par son accuracy.\")\n",
    "print(\"Problème: Expert 1 vote AUSSI pour les classes 9-16 (qu'il ne connaît pas).\")\n",
    "\n",
    "results_basic = model.evaluate(X_test_all, y_test_all)\n",
    "acc_basic = results_basic['accuracy']\n",
    "y_pred_basic = results_basic['y_pred']\n",
    "\n",
    "print(f\"\\nACCURACY = {acc_basic:.4f}\")\n",
    "print(classification_report(y_test_all, y_pred_basic, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MÉTHODE 2 : DW-CAV (Class-Aware Voting)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Chaque expert ne vote QUE pour les classes qu'il connaît.\")\n",
    "print(\"Expert 1 → vote sur [1-8], ignoré pour [9-16]\")\n",
    "print(\"Expert 2 → vote sur [9-16], ignoré pour [1-8]\")\n",
    "\n",
    "ALL_CLASSES = np.array(sorted(model.all_classes))\n",
    "n_classes = len(ALL_CLASSES)\n",
    "class_to_idx = {c: i for i, c in enumerate(ALL_CLASSES)}\n",
    "n_test = len(y_test_all)\n",
    "\n",
    "X_test_sc = model.scaler.transform(X_test_all)\n",
    "\n",
    "vote_dwcav = np.zeros((n_test, n_classes))\n",
    "\n",
    "for exp in model.experts:\n",
    "    clf = exp['clf']\n",
    "    w = exp['accuracy']\n",
    "    known = exp['classes']\n",
    "    proba = clf.predict_proba(X_test_sc)\n",
    "    expert_classes = clf.classes_\n",
    "\n",
    "    for i in range(n_test):\n",
    "        for j, c in enumerate(expert_classes):\n",
    "            if c in class_to_idx and c in known:\n",
    "                vote_dwcav[i, class_to_idx[c]] += w * proba[i, j]\n",
    "\n",
    "y_pred_dwcav = ALL_CLASSES[np.argmax(vote_dwcav, axis=1)]\n",
    "acc_dwcav = accuracy_score(y_test_all, y_pred_dwcav)\n",
    "\n",
    "print(f\"\\nACCURACY = {acc_dwcav:.4f}\")\n",
    "print(classification_report(y_test_all, y_pred_dwcav, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MÉTHODE 3 : Max-Confidence Selection\")\n",
    "print(\"=\"*60)\n",
    "print(\"On prend la prédiction de l'expert LE PLUS CONFIANT.\")\n",
    "print(\"Un expert qui ne connaît pas la classe → confiance basse → ignoré.\")\n",
    "\n",
    "y_pred_maxconf = np.zeros(n_test, dtype=int)\n",
    "conf_maxconf = np.zeros(n_test)\n",
    "\n",
    "for i in range(n_test):\n",
    "    best_conf = -1\n",
    "    best_pred = -1\n",
    "    for exp in model.experts:\n",
    "        clf = exp['clf']\n",
    "        x_i = X_test_sc[i:i+1]\n",
    "        pred_i = clf.predict(x_i)[0]\n",
    "        proba_i = clf.predict_proba(x_i)[0]\n",
    "        max_proba_i = np.max(proba_i)\n",
    "        if max_proba_i > best_conf:\n",
    "            best_conf = max_proba_i\n",
    "            best_pred = pred_i\n",
    "    y_pred_maxconf[i] = best_pred\n",
    "    conf_maxconf[i] = best_conf\n",
    "\n",
    "acc_maxconf = accuracy_score(y_test_all, y_pred_maxconf)\n",
    "\n",
    "print(f\"\\nACCURACY = {acc_maxconf:.4f}\")\n",
    "print(classification_report(y_test_all, y_pred_maxconf, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TRANSFERT DES SUPPORT VECTORS\n",
    "**Principe:** On extrait les SVs de Expert 1 (résumé compact de classes 1-8) et on les ajoute aux données de Expert 2. Ainsi Expert 2 connaît les 16 classes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"+E2 Transfert SVs \")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extraire les SVs de Expert 1\n",
    "expert1_clf = model.experts[0]['clf']\n",
    "X_known_train_sc = model.scaler.transform(X_known_train)\n",
    "sv_indices = expert1_clf.support_\n",
    "X_sv1 = X_known_train_sc[sv_indices]\n",
    "y_sv1 = y_known_train[sv_indices]\n",
    "\n",
    "print(f\"SVs from E1: {len(y_sv1)}\")\n",
    "print(f\"Classes inside SVs: {sorted(np.unique(y_sv1))}\")\n",
    "\n",
    "# E2 = old SVs + new data\n",
    "X_new_train_sc = model.scaler.transform(X_new_train)\n",
    "X_e2_transfer = np.vstack([X_sv1, X_new_train_sc])\n",
    "y_e2_transfer = np.hstack([y_sv1, y_new_train])\n",
    "\n",
    "\n",
    "expert2_transfer = SVC(\n",
    "    C=model.C, gamma=model.gamma, kernel='rbf',\n",
    "    class_weight='balanced', probability=True, random_state=42\n",
    ")\n",
    "expert2_transfer.fit(X_e2_transfer, y_e2_transfer)\n",
    "acc2_tr_train = accuracy_score(y_e2_transfer, expert2_transfer.predict(X_e2_transfer))\n",
    "print(f\"Train accuracy: {acc2_tr_train:.4f}, SVs: {len(expert2_transfer.support_)}\")\n",
    "\n",
    "y_pred_transfer = expert2_transfer.predict(X_test_sc)\n",
    "acc_transfer = accuracy_score(y_test_all, y_pred_transfer)\n",
    "\n",
    "print(f\"\\nACCURACY = {acc_transfer:.4f}\")\n",
    "print(classification_report(y_test_all, y_pred_transfer, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"DW-CAV + Transfert SVs\")\n",
    "\n",
    "print(\"E1 vote 1-8, E2 1-16\")\n",
    "\n",
    "vote_dwcav_tr = np.zeros((n_test, n_classes))\n",
    "\n",
    "#E1\n",
    "proba1 = expert1_clf.predict_proba(X_test_sc)\n",
    "ec1 = expert1_clf.classes_\n",
    "w1 = model.experts[0]['accuracy']\n",
    "for i in range(n_test):\n",
    "    for j, c in enumerate(ec1):\n",
    "        if c in class_to_idx and c in set(KNOWN_CLASSES):\n",
    "            vote_dwcav_tr[i, class_to_idx[c]] += w1 * proba1[i, j]\n",
    "\n",
    "# E2 \n",
    "proba2 = expert2_transfer.predict_proba(X_test_sc)\n",
    "ec2 = expert2_transfer.classes_\n",
    "w2 = acc2_tr_train\n",
    "for i in range(n_test):\n",
    "    for j, c in enumerate(ec2):\n",
    "        if c in class_to_idx:\n",
    "            vote_dwcav_tr[i, class_to_idx[c]] += w2 * proba2[i, j]\n",
    "\n",
    "y_pred_dwcav_tr = ALL_CLASSES[np.argmax(vote_dwcav_tr, axis=1)]\n",
    "acc_dwcav_tr = accuracy_score(y_test_all, y_pred_dwcav_tr)\n",
    "\n",
    "print(f\"\\nACCURACY = {acc_dwcav_tr:.4f}\")\n",
    "print(classification_report(y_test_all, y_pred_dwcav_tr, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# RÉSULTATS COMPARATIFS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    (\"Vote Basique\",         y_pred_basic,    acc_basic,    '#E53935'),\n",
    "    (\"DW-CAV\",               y_pred_dwcav,    acc_dwcav,    '#2196F3'),\n",
    "    (\"Max-Confidence\",       y_pred_maxconf,  acc_maxconf,  '#4CAF50'),\n",
    "    (\"E2 transféré seul\",    y_pred_transfer, acc_transfer, '#FF9800'),\n",
    "    (\"DW-CAV + Transfert\",   y_pred_dwcav_tr, acc_dwcav_tr, \"#891C9C\"),\n",
    "]\n",
    "\n",
    "# Confusion matrices\n",
    "top3 = [methods[1], methods[3], methods[4]]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 7))\n",
    "for ax, (name, y_pred, acc, _) in zip(axes, top3):\n",
    "    cm = confusion_matrix(y_test_all, y_pred, labels=ALL_CLASSES)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_norm = np.nan_to_num(cm_norm)\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=ALL_CLASSES.astype(int),\n",
    "                yticklabels=ALL_CLASSES.astype(int),\n",
    "                ax=ax, vmin=0, vmax=1, cbar=False, annot_kws={'size': 8})\n",
    "    ax.set_xlabel('Prédite')\n",
    "    ax.set_ylabel('Réelle')\n",
    "    ax.set_title(f\"{name}\\nAccuracy: {acc:.2%}\", fontsize=13, fontweight='bold')\n",
    "    ax.axhline(y=len(KNOWN_CLASSES), color='red', lw=2, ls='--')\n",
    "    ax.axvline(x=len(KNOWN_CLASSES), color='red', lw=2, ls='--')\n",
    "plt.suptitle(\"Meilleures Stratégies — Learn++.NC\", fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "names_short = ['Vote\\nBasic', 'DW-CAV', 'Max-\\nConf.', 'E2 transf.\\nseul', 'DW-CAV\\n+ Transfert']\n",
    "accs_all = [m[2] for m in methods]\n",
    "colors_all = [m[3] for m in methods]\n",
    "\n",
    "# Global\n",
    "ax = axes[0]\n",
    "bars = ax.bar(names_short, accs_all, color=colors_all, edgecolor='black', width=0.55)\n",
    "for bar, a in zip(bars, accs_all):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{a:.1%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "ax.set_ylim([0, 1.15])\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Accuracy Globale (16 classes)', fontsize=14, fontweight='bold')\n",
    "ax.axhline(1.0, color='gray', ls='--', alpha=0.3)\n",
    "\n",
    "# Connues vs Nouvelles\n",
    "ax = axes[1]\n",
    "acc_groups = []\n",
    "for name, y_pred, acc, _ in methods:\n",
    "    mk = n\n",
    "    p.isin(y_test_all, KNOWN_CLASSES)\n",
    "    mn = np.isin(y_test_all, NEW_CLASSES)\n",
    "    acc_groups.append((accuracy_score(y_test_all[mk], y_pred[mk]),\n",
    "                       accuracy_score(y_test_all[mn], y_pred[mn])))\n",
    "\n",
    "x = np.arange(5)\n",
    "w = 0.3\n",
    "bars1 = ax.bar(x - w/2, [a[0] for a in acc_groups], w, label='known (1-8)', color='#2196F3', edgecolor='black')\n",
    "bars2 = ax.bar(x + w/2, [a[1] for a in acc_groups], w, label='unknown(9-16)', color='#FF9800', edgecolor='black')\n",
    "for bar, a in zip(bars1, [a[0] for a in acc_groups]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{a:.1%}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "for bar, a in zip(bars2, [a[1] for a in acc_groups]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{a:.1%}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names_short, fontsize=9)\n",
    "ax.set_ylim([0, 1.15])\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('known vs unknown classes', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('accuracy_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "\n",
    "for idx, (name, y_pred, acc, col) in enumerate(methods):\n",
    "    class_accs = []\n",
    "    for c in ALL_CLASSES:\n",
    "        mask = y_test_all == c\n",
    "        class_accs.append(np.mean(y_pred[mask] == c) if np.sum(mask) > 0 else 0)\n",
    "    offset = (idx - 2) * 0.16\n",
    "    ax.bar(np.arange(n_classes) + offset, class_accs, width=0.16,\n",
    "           label=f'{name} ({acc:.1%})', color=col, edgecolor='black', alpha=0.85)\n",
    "\n",
    "ax.set_xticks(range(n_classes))\n",
    "ax.set_xticklabels([int(c) for c in ALL_CLASSES])\n",
    "ax.set_xlabel('Classe', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Accuracy par Classe — 5 Stratégies', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim([0, 1.15])\n",
    "ax.legend(fontsize=9, loc='lower right')\n",
    "ax.axvline(x=7.5, color='red', ls='--', lw=2, alpha=0.5)\n",
    "ax.text(3.5, 1.08, 'CONNUES', ha='center', fontsize=12, color='#2196F3', fontweight='bold')\n",
    "ax.text(11.5, 1.08, 'NOUVELLES', ha='center', fontsize=12, color='#FF9800', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('per_class_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SAUVEGARDE\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le MEILLEUR modèle = Expert transféré (97.7%)\n",
    "# On sauvegarde : le SVM, le scaler, et les métadonnées\n",
    "best_model = {\n",
    "    'clf': expert2_transfer,\n",
    "    'scaler': model.scaler,\n",
    "    'classes': sorted(model.all_classes),\n",
    "    'accuracy_train': acc2_tr_train,\n",
    "    'C': model.C,\n",
    "    'gamma': model.gamma,\n",
    "    'method': 'SV Transfer',\n",
    "    'n_sv': len(expert2_transfer.support_),\n",
    "}\n",
    "\n",
    "with open('learnpp_sv_transfer.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"Modèle sauvegardé: learnpp_sv_transfer.pkl\")\n",
    "print(f\"  Méthode: SV Transfer\")\n",
    "print(f\"  Classes: {best_model['classes']}\")\n",
    "print(f\"  Accuracy train: {best_model['accuracy_train']:.4f}\")\n",
    "print(f\"  SVs: {best_model['n_sv']}\")\n",
    "\n",
    "files.download('learnpp_sv_transfer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for f in ['optuna_results.png', 'experts_summary.png', 'confusion_matrix.png',\n",
    "          'confusion_comparison.png', 'accuracy_comparison.png', 'per_class_comparison.png',\n",
    "          'confidence_distribution.png', 'vote_examples.png', 'class_performance.png']:\n",
    "    if os.path.exists(f):\n",
    "        files.download(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
